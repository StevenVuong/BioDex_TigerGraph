{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3de1b-30c7-4782-9b52-5ac5be650d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.metrics import TopKCategoricalAccuracy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541a3b6-8947-4916-9a80-fb77d1e7ab0c",
   "metadata": {},
   "source": [
    "### Define Parameters/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948927ca-0d64-486d-9ceb-95f87b952588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model name; other option is 'MobileNetV3Large'\n",
    "MODEL_NAME = 'InceptionResNetV2' \n",
    "\n",
    "# Set image width, height\n",
    "if MODEL_NAME == 'InceptionResNetV2':\n",
    "    IMG_WIDTH, IMG_HEIGHT = 299, 299\n",
    "    from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "    \n",
    "if MODEL_NAME == 'MobileNetV3Large':\n",
    "    IMG_WIDTH, IMG_HEIGHT = 224, 224 \n",
    "    from keras.applications.mobilenet_v3 import MobileNetV3Large, preprocess_input\n",
    "\n",
    "# set model parameters\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47181498-cddd-4230-8712-7b7819918188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supercategories:'Plant', 'Animalia', 'Arachnid', 'Mollusk', 'Mammal', 'Fungi', 'Reptile', 'Insect', 'Ray-finned Fishe', 'Birds', 'Amphibia'\n",
    "# set train directory\n",
    "SUPERCATEGORY = 'Birds'\n",
    "IMG_TRAIN_DIR = os.path.join('./data/train_supercategory/', SUPERCATEGORY)\n",
    "NUM_CLASSES = len(os.listdir(IMG_TRAIN_DIR))\n",
    "print(f'There are {NUM_CLASSES} classes in {IMG_TRAIN_DIR}')\n",
    "\n",
    "IMG_VAL_DIR = os.path.join('./data/val_supercategory/', SUPERCATEGORY)\n",
    "IMG_TRAIN_MINI_DIR = os.path.join('./data/train_supercategory/', SUPERCATEGORY)\n",
    "\n",
    "MODEL_SAVEDIR = os.path.join('./models/full/', SUPERCATEGORY)\n",
    "print('Model Savedir:', MODEL_SAVEDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45a4c6-e6aa-4e37-b2d4-0e8449ccdc15",
   "metadata": {},
   "source": [
    "### Build DataGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b641f37-28b7-4359-8407-cc167c9a1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build train datagen\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input, # preprocess input already scales to [-1,1]\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    ")\n",
    "\n",
    "# attach the generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = IMG_TRAIN_DIR,\n",
    "    target_size = (IMG_WIDTH, IMG_HEIGHT),\n",
    "    color_mode='rgb',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "assert '.ipynb_checkpoints' not in train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce8b84-dbae-4a26-a0f0-a7d68b172906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for val; no preprocessing for this one..\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input, # preprocess input already scales to [-1,1]\n",
    ")\n",
    "\n",
    "# attach the generator\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory = IMG_VAL_DIR,\n",
    "    target_size = (IMG_WIDTH, IMG_HEIGHT),\n",
    "    color_mode='rgb',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "assert '.ipynb_checkpoints' not in val_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0016fa-ea40-44b9-a75d-aff7760cca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now add on mini\n",
    "train_mini_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input, # preprocess input already scales to [-1,1]\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    ")\n",
    "\n",
    "# attach the datagen; we will try to build a model with birds first\n",
    "train_mini_generator = train_mini_datagen.flow_from_directory(\n",
    "    directory = IMG_TRAIN_MINI_DIR,\n",
    "    target_size = (IMG_WIDTH, IMG_HEIGHT),\n",
    "    color_mode='rgb',\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "assert '.ipynb_checkpoints' not in train_mini_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d6feb-99f7-47ba-8d61-92b592a58106",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25ab6e-2eae-4f9d-84f3-d46d87922753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == 'InceptionResNetV2':\n",
    "    base_model=InceptionResNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False, \n",
    "        input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "    )\n",
    "\n",
    "if MODEL_NAME == 'MobileNetV3Large':\n",
    "    # import basemodel Inception ResnetV2 with imagenet weights\n",
    "    base_model=MobileNetV3Large(\n",
    "        weights='imagenet',\n",
    "        include_top=False, \n",
    "        input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "    )\n",
    "    \n",
    "print(f\"Number of layers: {len(base_model.layers)}\")\n",
    "base_model.output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c75a6a-0fe6-4445-a667-9b115dc2ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach on top layer\n",
    "x = base_model.output\n",
    "# flatten and dense\n",
    "x = Flatten()(x)\n",
    "output = Dense(NUM_CLASSES, activation='softmax')(x) # number of classes\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a707c2-8086-4705-9688-942506f4d921",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Approach to training\n",
    "-  fine-tune train top layer (full dataset)\n",
    "-  fine-tune train all layers (full dataset)\n",
    "-  fine-tune top layer (mini balanced dataset)\n",
    "-  fine-tune all layers (mini balanced dataset)\n",
    "\n",
    "### Train Top Layer with Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec744f5-2271-4e7a-9259-af387d54de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all base layers at first\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58aabf-c452-420c-ba65-ad10c6a82944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decay every 2 epochs (2* each step; a step is where each gradient update happens)\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.045, decay_steps=(2*train_generator.samples//BATCH_SIZE) , decay_rate=0.94)\n",
    "\n",
    "# compile model\n",
    "top_k_metric = TopKCategoricalAccuracy(k=5)\n",
    "\n",
    "# compile model\n",
    "model.compile(\n",
    "    optimizer=RMSprop(momentum=0.9, learning_rate=lr_schedule), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy', top_k_metric]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78395e14-de67-438f-bbc0-23caa1d424be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best checkpoints\n",
    "print(f'Saving models in {MODEL_SAVEDIR}')\n",
    "checkpoint = ModelCheckpoint(filepath=MODEL_SAVEDIR, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# fit model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples//BATCH_SIZE,\n",
    "    epochs = 20,\n",
    "    callbacks=[checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f8d35-df54-42f5-82c1-9c755318f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return evaluation metrics\n",
    "score = model.evaluate(val_generator)\n",
    "\n",
    "print (\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n",
    "print (\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c22ad-3721-471b-8792-1cbe19aa9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26647510-fa7c-4bc1-a25c-7a609bf0099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab286a-14d0-4966-a126-ebcadbb37ac3",
   "metadata": {},
   "source": [
    "### Train Full Model With Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a15d0b-5909-4e62-b8d0-aa8515cf4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze and train on all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# re-compile model to refresh learning rate scheduler\n",
    "model.compile(\n",
    "    optimizer=RMSprop(momentum=0.9, learning_rate=lr_schedule), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy', top_k_metric]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15902851-d093-4794-ba42-19baeb7fe304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples//BATCH_SIZE,\n",
    "    epochs = 100,\n",
    "    callbacks=callbacks_list\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20acd814-51bb-4389-af79-bd0224428d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return evaluation metrics\n",
    "score = model.evaluate(val_generator)\n",
    "print(score)\n",
    "\n",
    "print (\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n",
    "print (\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02bfb9-50e0-4d57-97bc-6c3a54be6536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
