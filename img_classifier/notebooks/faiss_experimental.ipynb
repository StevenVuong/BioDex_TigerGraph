{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a106fcdd-c948-4f5d-9991-d3a8686723ab",
   "metadata": {},
   "source": [
    "## Approach\n",
    "Use SIFT to obtain image embeddings each bird and store them in FAISS; then see if we can correctly find bird species given an image.\n",
    "\n",
    "To start: Install packages by running `pip install pytorch opencv-contrib-python` in a terminal window `conda install -c pytorch faiss-gpu`.\n",
    "OReilley's [Practical Deep Learning Book](https://www.oreilly.com/library/view/practical-deep-learning/9781492034858/ch04.html) chapter 4 gives us some guidance here also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196709e-d1b9-47bb-ba08-b29f3f627cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import faiss\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d767b-0af6-4784-851f-ccea2afc3154",
   "metadata": {},
   "source": [
    "### Produce Embeddings of All our Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782fb517-ea07-4af9-9b49-a7c1bd4bf0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "# load model to produce our embeddings\n",
    "model = hub.KerasLayer(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5\", trainable=False) # targetsize 299 for this\n",
    "\n",
    "def extract_features(img_path, model, target_size=(299, 299)):\n",
    "    \"\"\"Load image to arary, resize, scale and expand dimensions.\"\"\"\n",
    "    img = image.load_img(img_path, target_size = target_size)\n",
    "    img = image.img_to_array(img)\n",
    "    \n",
    "    # scale to [|0, 1]\n",
    "    img = img / 255\n",
    "    \n",
    "    # expand dim\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    \n",
    "    # get embeddings for and flatten\n",
    "    img_embeddings = model(img)\n",
    "    img_embeddings = img_embeddings.numpy()[0]\n",
    "        \n",
    "    # normalise images\n",
    "    img_embeddings /= norm(img_embeddings)\n",
    "\n",
    "    return img_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c134d-fb19-420c-8743-e15d382b765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "def get_file_list(root_dir):\n",
    "    file_list = []\n",
    "    counter = 1\n",
    "    for root, directories, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(ext in filename for ext in extensions):\n",
    "                img_path = os.path.join(root, filename)\n",
    "                if '.ipynb' in img_path: continue\n",
    "                file_list.append(img_path)\n",
    "                counter += 1\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02cb28b-94d7-4936-80d0-55324cbb545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datasets; do birds as it is smaller subset\n",
    "root_dir = './data/train_mini_supercategory/Animalia' \n",
    "filenames = sorted(get_file_list(root_dir))\n",
    "num_images = len(filenames)\n",
    "print(num_images, 'files found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88679b-beb7-460a-ad16-c114fbd15c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variable to store all our features\n",
    "feature_list = []\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    feature_list.append(extract_features(filenames[i], model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0e65e-44f7-4c27-be56-487218bbdc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle our files\n",
    "# pickle.dump(feature_list, open('./models/features-inceptionv3.pickle', 'wb'))\n",
    "# pickle.dump(filenames, open('./models/filenames.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488f47f-a20f-4cb3-95d8-97163e53b64f",
   "metadata": {},
   "source": [
    "MobileNet is much faster than ResNet for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2d256-324e-4adf-bb33-0088866442f9",
   "metadata": {},
   "source": [
    "### View These Images\n",
    "Helper functions found [here](https://blog.csdn.net/guaguastd/article/details/107777972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f44e4b-1730-4440-b1f7-4f511715e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load features list and filenames\n",
    "with open('./models/features-inceptionv3.pickle', 'rb') as pickle_file:\n",
    "    feature_list = pickle.load(pickle_file)\n",
    "feature_list = np.array(feature_list)\n",
    "    \n",
    "with open('./models/filenames.pickle', 'rb') as pickle_file:\n",
    "    filenames = pickle.load(pickle_file)\n",
    "num_images = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c60ea6-5460-4483-813f-d3ed38be61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classname_filename(str):\n",
    "    return str.split('/')[-2]\n",
    "\n",
    "def plot_images(filenames, distances):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(mpimg.imread(filename))\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    columns = 4\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        if i==0:\n",
    "            ax.set_title(\"Query Image \\n\" + classname_filename(filenames[i]))\n",
    "        else:\n",
    "            ax.set_title(\"Similar Image\\n\" + classname_filename(filenames[i]) + \"\\nDistance: \" + f\"{distances[i]:.2f}\")\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0505cf-bd11-4646-9c3e-8884b439a079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get nearest neighbours and plot them\n",
    "neighbors = NearestNeighbors(n_neighbors=5, algorithm='brute', metric='euclidean').fit(feature_list)\n",
    "\n",
    "for i in range(3):\n",
    "    random_image_index = random.randint(0,num_images-1)\n",
    "    distances, indices = neighbors.kneighbors([feature_list[random_image_index]])\n",
    "    # don't take the first closest image as it will be the same image\n",
    "    similar_image_paths = [filenames[random_image_index]] +[filenames[indices[0][i]] for i in range(1,4)]\n",
    "    plot_images(similar_image_paths, distances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930a62d-329c-429b-a7f2-e66edb0fb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_1_topn(indexes, n=5):\n",
    "\n",
    "    times_top1 = 0\n",
    "    times_top5 = 0\n",
    "\n",
    "    for i in tqdm(I):\n",
    "\n",
    "        actual_name = classname_filename(filenames[i[0]])\n",
    "\n",
    "        if actual_name == classname_filename(filenames[i[1]]):\n",
    "            times_top1 += 1\n",
    "            times_top5 += 1\n",
    "            continue\n",
    "\n",
    "        if actual_name in [classname_filename(filenames[ii]) for ii in i[1:]]:\n",
    "            times_top5 += 1\n",
    "            continue\n",
    "            \n",
    "    return times_top1, times_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa7252-544d-4397-aa7d-f8f621ad59d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "# bruteforce; figure out times top1, top5. Really slow though, definitely be going with faiss\n",
    "all_indices=[]\n",
    "for i in tqdm(range(0,7100)):\n",
    "    distances, indices = neighbors.kneighbors([feature_list[i]])\n",
    "    all_indices.append(indices)\n",
    "all_indices = np.array(all_indices)\n",
    "\n",
    "times_top1, times_top5 = get_top_1_topn(all_indices, 5)\n",
    "print('Times top1:', times_top1, '\\nTimes top5:', times_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72cb82-73f3-4a2b-9bc4-a60bdf897673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA over the features\n",
    "num_feature_dimensions = 50      # Set the number of features\n",
    "pca = PCA(n_components = num_feature_dimensions)\n",
    "pca.fit(feature_list)\n",
    "feature_list_compressed = pca.transform(feature_list)\n",
    "\n",
    "# For speed and clarity, we'll look at first 3000/~7000 images\n",
    "num_samples = 3000\n",
    "selected_features = feature_list_compressed[:num_samples]\n",
    "selected_filenames = filenames[:num_samples]\n",
    "# get classids and map them to colors to plot\n",
    "selected_class_ids = filenames[:num_samples]\n",
    "selected_class_ids = [scid.split('/')[-2] for scid in selected_class_ids if scid != '.ipynb_checkpoints']\n",
    "idx_classid_map = {cid:idx for idx, cid in enumerate(set(selected_class_ids))}\n",
    "class_id_colors = [idx_classid_map[cid] for cid in selected_class_ids]\n",
    "\n",
    "# get tsne results\n",
    "tsne_results = TSNE(n_components=2, verbose=1,metric='euclidean').fit_transform(selected_features)\n",
    "\n",
    "# Plot a scatter plot from the generated t-SNE results\n",
    "colormap = plt.cm.get_cmap('coolwarm')\n",
    "scatter_plot = plt.scatter(tsne_results[:,0],tsne_results[:,1], c = class_id_colors, cmap=colormap)\n",
    "plt.colorbar(scatter_plot)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf454c1-db2d-43fa-abfc-10d07e658689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "from matplotlib.offsetbox import (OffsetImage, AnnotationBbox)\n",
    "\n",
    "def plot_images_in_2d(x, y, image_paths, axis=None, zoom=1):\n",
    "    if axis is None:\n",
    "        axis = plt.gca()\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    for x0, y0, image_path in zip(x, y, image_paths):\n",
    "        image = Image.open(image_path)\n",
    "        image.thumbnail((100, 100), Image.ANTIALIAS)\n",
    "        img = OffsetImage(image, zoom=zoom)\n",
    "        anno_box = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n",
    "        axis.add_artist(anno_box)\n",
    "    axis.update_datalim(np.column_stack([x, y]))\n",
    "    axis.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206e0bc-f3c4-498a-8b81-05cba8f31a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(45,45))\n",
    "plot_images_in_2d(tsne_results[:,0], tsne_results[:,1], selected_filenames)\n",
    "# plt.savefig('inceptionv3-normalized.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601f35a-c16b-4ba1-9b36-d35db9b0ba0b",
   "metadata": {},
   "source": [
    "### PCA To Reduce Dimensionality\n",
    "[Link to Git](https://github.com/PracticalDL/Practical-Deep-Learning-Book/blob/master/code/chapter-4/3-reduce-feature-length-with-pca.ipynb) of O'Reilley book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee2b68-e064-4784-99bf-47f1c5d12b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature_dimensions=200 # reduce to 200 dimensions\n",
    "pca = PCA(n_components = num_feature_dimensions)\n",
    "pca.fit(feature_list)\n",
    "feature_list_compressed = pca.transform(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753d2ee-2231-45b3-9578-663ce4f93df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise importance of first 200 dimensions\n",
    "\n",
    "matplotlib.style.use('seaborn')\n",
    "plt.plot(range(1,201),pca.explained_variance_ratio_,'o--', markersize=4)\n",
    "plt.title ('Variance for each PCA dimension')\n",
    "plt.xlabel('PCA Dimensions')\n",
    "plt.ylabel('Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f0264-ff75-4de7-b088-1c9755b91290",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,201),pca.explained_variance_ratio_.cumsum(),'o--', markersize=4)\n",
    "plt.title ('Cumulative Variance with each PCA dimension')\n",
    "plt.xlabel('PCA Dimensions')\n",
    "plt.ylabel('Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8125bf60-23af-45eb-84a3-231f9a587c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the classname\n",
    "def classname(str):\n",
    "    return str.split('/')[-2]\n",
    "\n",
    "# Helper function that calculates accuracy using the nearest neighbors brute force algorithm\n",
    "def calculate_accuracy(feature_list):\n",
    "    num_nearest_neighbors = 5\n",
    "    correct_prediction = 0\n",
    "    incorrect_prediction = 0\n",
    "    neighbors = NearestNeighbors(n_neighbors=num_nearest_neighbors,\n",
    "                                 algorithm='brute',\n",
    "                                 metric='euclidean').fit(feature_list)\n",
    "    start = time.time()\n",
    "    for i in range(len(feature_list)):\n",
    "        distances, indices = neighbors.kneighbors([feature_list[i]])\n",
    "        for j in range(1, num_nearest_neighbors):\n",
    "            if (classname(filenames[i]) == classname(\n",
    "                    filenames[indices[0][j]])):\n",
    "                correct_prediction += 1\n",
    "            else:\n",
    "                incorrect_prediction += 1\n",
    "    end = time.time()\n",
    "    accuracy = round(\n",
    "        100.0 * correct_prediction /\n",
    "        (1.0 * correct_prediction + incorrect_prediction), 2), end - start\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149fd1c-e8f4-49ff-aac8-0b4af0aaa845",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dimensions = [1,2,3,4,5,10,20,50,75,100,150,200]\n",
    "pca_accuracy = []\n",
    "pca_time = []\n",
    "\n",
    "for dimensions in pca_dimensions:\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components = dimensions)\n",
    "    pca.fit(feature_list)\n",
    "    feature_list_compressed = pca.transform(feature_list[:])\n",
    "    # Calculate accuracy over the compressed features\n",
    "    accuracy, time_taken = calculate_accuracy(feature_list_compressed[:])\n",
    "    pca_time.append(time_taken)\n",
    "    pca_accuracy.append(accuracy)\n",
    "    print(\"For PCA Dimensions = \", dimensions, \",\\tAccuracy = \",accuracy,\"%\", \",\\tTime = \", pca_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e7f94b-7b6c-4c06-891a-c0315ed524fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca_time, pca_accuracy,'o--', markersize=4)\n",
    "for label, x, y in zip(pca_dimensions, pca_time,pca_accuracy):\n",
    "    plt.annotate(label, xy=(x, y), ha='right', va='bottom')\n",
    "plt.title ('Test Time vs Accuracy for each PCA dimension')\n",
    "plt.xlabel('Test Time')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da03d2a4-e705-4d5e-933a-34ed5b03b384",
   "metadata": {},
   "source": [
    "Decide to go with 100 features, as the benefits flatten for the amount of increased test time. <br>\n",
    "The dimensions should correspond with the `filenames` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d4737-aa24-42c1-9a92-664e75ef4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244e4d0-2be0-4947-8324-214d385da7de",
   "metadata": {},
   "source": [
    "### FAISS For ANN Search (with GPU's)\n",
    "Another Option is Spotify's [annoy](https://github.com/spotify/annoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e473f-40f2-4445-9819-af8c18cb6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature_dimensions=100 # reduce to 100 dimensions\n",
    "pca = PCA(n_components = num_feature_dimensions)\n",
    "\n",
    "pca.fit(feature_list)\n",
    "feature_list_compressed = pca.transform(feature_list)\n",
    "assert feature_list_compressed.shape == (num_images, num_feature_dimensions)\n",
    "\n",
    "feature_list_compressed = feature_list_compressed.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111710d0-4f64-40b5-b2b4-dea64ff82786",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = np.array(feature_list).astype(np.float32)\n",
    "feature_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2082edb-e27b-48f3-a7d4-0531070eaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_KEY = \"Flat\"\n",
    "use_gpu = False # false in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c79de-e57d-4aa4-801b-81e83255ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build faiss index\n",
    "index = faiss.index_factory(2048, INDEX_KEY)\n",
    "\n",
    "if use_gpu:\n",
    "    print('Using GPU')\n",
    "    # if this fails, it means that the GPU version was not comp\n",
    "    assert faiss.StandardGpuResources, \\\n",
    "        \"FAISS was not compiled with GPU support, or loading _swigfaiss_gpu.so failed\"\n",
    "    res = faiss.StandardGpuResources()\n",
    "    dev_no = 0\n",
    "\n",
    "    # transfer to GPU (may be partial)\n",
    "    index = faiss.index_cpu_to_gpu(res, dev_no, index)\n",
    "    params = faiss.GpuParameterSpace()\n",
    "\n",
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd790e-1054-4c72-b172-55722a635105",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1 # timeit\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa37a8-dc7b-4423-b68d-17418c3fffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce10ea-cfb4-4934-9c39-3eecfe3d8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "# add indexes\n",
    "#index.add(feature_list_compressed)\n",
    "index.add(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f40dd-1e84-4098-9bd7-39ccaa22b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "D, I = index.search(feature_list[:5], 5) # sanity check, 5 Nearest-Neighbours\n",
    "print(I) # indexes\n",
    "print(D) # distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d59cec-fb6b-4ea5-84e0-0fe375722d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(feature_list[:5], 5) # sanity check, 5 Nearest-Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69bf51-2ef0-4055-8fcb-733a5ebc96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "I[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcab3e-483e-42cf-b1a9-51397957d159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similar_image_paths = [filenames[random_image_index]] +[filenames[indices[0][i]] for i in range(1,4)]\n",
    "# plot_images(similar_image_paths, distances[0])\n",
    "\n",
    "for i, d in zip(I, D):\n",
    "    similar_image_paths = [filenames[ii] for ii in i]\n",
    "    plot_images(similar_image_paths, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3ebfe-7e31-4c29-8ab4-ff363d60a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(feature_list[:7000], 5) # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b66c9-3133-40a2-80aa-4827d2265005",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "# of n images, we will count the amount that match top-1, top 5\n",
    "D, I = index.search(feature_list[:7000], 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9cb7df-0d2f-41fe-b933-c0464411e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_top1, times_top5 = get_top_1_topn(I, 5)\n",
    "print('Times top1:', times_top1, '\\nTimes top5:', times_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8071e2c-d8ac-4da7-8179-55bbad7ffa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#faiss.write_index(faiss.index_gpu_to_cpu(gpu_index), writer.data) # if gpu\n",
    "faiss.write_index(index, './models/faiss.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c026d4-919d-40c6-b318-ea1b49950f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index('./models/faiss.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e520d1-0999-4b31-9ffd-2411bafcf43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
