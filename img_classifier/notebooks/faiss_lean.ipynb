{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3d12f-5d45-4ba7-bbf1-b5e1ea4fed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c78207-4899-44e3-afee-e660cfc7a6c2",
   "metadata": {},
   "source": [
    "#### Get embedding of train mini images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2d22b-ad20-490d-bcb0-7dfb07c628d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# load model to produce our embeddings\n",
    "model = hub.KerasLayer(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5\", trainable=False) # targetsize 299 for this\n",
    "\n",
    "def extract_features(img_path, model, target_size=(299, 299)):\n",
    "    \"\"\"Load image to arary, resize, scale and expand dimensions.\"\"\"\n",
    "    img = image.load_img(img_path, target_size = target_size)\n",
    "    img = image.img_to_array(img)\n",
    "    \n",
    "    # scale to [|0, 1]\n",
    "    img = img / 255\n",
    "    \n",
    "    # expand dim\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    \n",
    "    # get embeddings for and flatten\n",
    "    img_embeddings = model(img)\n",
    "    img_embeddings = img_embeddings.numpy()[0]\n",
    "        \n",
    "    # normalise images\n",
    "    img_embeddings /= norm(img_embeddings)\n",
    "\n",
    "    return img_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f455b-d4a8-4caf-b534-5dc0a1a51ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of images in directory, including nested directories within dir\n",
    "extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "def get_file_list(root_dir):\n",
    "    file_list = []\n",
    "    counter = 1\n",
    "    for root, directories, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(ext in filename for ext in extensions):\n",
    "                img_path = os.path.join(root, filename)\n",
    "                if '.ipynb' in img_path: continue\n",
    "                file_list.append(img_path)\n",
    "                counter += 1\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac15f1b-1c37-41df-a74c-309f286378e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datasets; do birds as it is smaller subset\n",
    "root_dir = './data/train_mini_supercategory/' \n",
    "filenames = sorted(get_file_list(root_dir))\n",
    "num_images = len(filenames)\n",
    "print(num_images, 'files found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c8f3b-3178-4534-b127-a18de96a5623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variable to store all our features\n",
    "feature_list = []\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    feature_list.append(extract_features(filenames[i], model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799acd64-df9e-49c3-a0d4-4c973cfaf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle our files\n",
    "pickle.dump(feature_list, open('./models/trainmini-features-inceptionv3.pickle', 'wb'))\n",
    "pickle.dump(filenames, open('./models/trainmini-filenames.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758bc7c-478a-4685-9f28-03677d9bb78e",
   "metadata": {},
   "source": [
    "#### Load Pickle and turn to Faiss Index And Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0073706-11b1-477d-9a6b-daabcf9f4919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd17ab-f071-4666-92bc-dfad7710f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_1_topn(indexes, n=5):\n",
    "    '''Ranking metric; of the returned top 5 results, how many times the correct\n",
    "    result is in the top 1, and top 5.'''\n",
    "\n",
    "    times_top1 = 0\n",
    "    times_top5 = 0\n",
    "\n",
    "    for i in tqdm(I):\n",
    "\n",
    "        actual_name = classname_filename(filenames[i[0]])\n",
    "\n",
    "        if actual_name == classname_filename(filenames[i[1]]):\n",
    "            times_top1 += 1\n",
    "            times_top5 += 1\n",
    "            continue\n",
    "\n",
    "        if actual_name in [classname_filename(filenames[ii]) for ii in i[1:]]:\n",
    "            times_top5 += 1\n",
    "            continue\n",
    "            \n",
    "    return times_top1, times_top5\n",
    "\n",
    "def classname_filename(str):\n",
    "    return str.split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99872b2a-7f15-4d56-b028-4b5de0cee198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load features list and filenames\n",
    "with open('./models/trainmini-features-inceptionv3.pickle', 'rb') as pickle_file:\n",
    "    feature_list = pickle.load(pickle_file)\n",
    "feature_list = np.array(feature_list).astype(np.float32)\n",
    "    \n",
    "with open('./models/trainmini-filenames.pickle', 'rb') as pickle_file:\n",
    "    filenames = pickle.load(pickle_file)\n",
    "num_images = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1858bb-d6b7-4393-85e3-53e28594f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10311ba0-d919-45a0-9a06-d824634f69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_KEY = \"Flat\"\n",
    "use_gpu = True # false in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6571a2-60bd-42ea-a776-3f9c5b67629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build faiss index\n",
    "index = faiss.index_factory(2048, INDEX_KEY)\n",
    "\n",
    "if use_gpu:\n",
    "    print('Using GPU')\n",
    "    # if this fails, it means that the GPU version was not comp\n",
    "    assert faiss.StandardGpuResources, \\\n",
    "        \"FAISS was not compiled with GPU support, or loading _swigfaiss_gpu.so failed\"\n",
    "    res = faiss.StandardGpuResources()\n",
    "    dev_no = 0\n",
    "\n",
    "    # transfer to GPU (may be partial)\n",
    "    index = faiss.index_cpu_to_gpu(res, dev_no, index)\n",
    "    params = faiss.GpuParameterSpace()\n",
    "\n",
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae7551-3ae0-48c8-a756-b5cb9255e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "# add indexes\n",
    "index.add(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d0db2-cfde-499d-9526-c18b6ec4a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "D, I = index.search(feature_list[:5], 5) # sanity check, 5 Nearest-Neighbours\n",
    "print(I) # indexes\n",
    "print(D) # distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dccfa5-0caf-462c-9c09-79c3e7cadfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "# of n images, we will count the amount that match top-1, top 5\n",
    "D, I = index.search(feature_list[:100_000], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78b152-958e-4b42-98cb-bd3d4efb90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_top1, times_top5 = get_top_1_topn(I, 5)\n",
    "print('Times top1:', times_top1, '\\nTimes top5:', times_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b233666-9434-40c0-85db-ce5ba98d78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gou; convert to cpu to save\n",
    "# 4gb when we save the entire index \n",
    "sys.getsizeof(index)\n",
    "if use_gpu:\n",
    "    faiss.write_index(faiss.index_gpu_to_cpu(index), './models/trainmini-faiss.index')\n",
    "if not use_gpu:   \n",
    "    faiss.write_index(index, './models/trainmini-faiss.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58feebfd-df91-48dc-9181-8f52e2ea020d",
   "metadata": {},
   "source": [
    "#### Test FAISS with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f76d0-0287-40f1-b762-c2befd64112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "num_feature_dimensions=128 # reduce to 128 dimensions\n",
    "pca = PCA(n_components = num_feature_dimensions)\n",
    "pca.fit(feature_list) # train PCA\n",
    "feature_list_compressed = pca.transform(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9bca8-6a59-427a-a28a-55192a621dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca, open(\"./models/pca-trainmini.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc9faf-ddce-4ed9-b0e7-3bbd15a9aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build faiss index\n",
    "index = faiss.index_factory(num_feature_dimensions, INDEX_KEY)\n",
    "\n",
    "if use_gpu:\n",
    "    print('Using GPU')\n",
    "    # if this fails, it means that the GPU version was not comp\n",
    "    assert faiss.StandardGpuResources, \\\n",
    "        \"FAISS was not compiled with GPU support, or loading _swigfaiss_gpu.so failed\"\n",
    "    res = faiss.StandardGpuResources()\n",
    "    dev_no = 0\n",
    "\n",
    "    # transfer to GPU (may be partial)\n",
    "    index = faiss.index_cpu_to_gpu(res, dev_no, index)\n",
    "    params = faiss.GpuParameterSpace()\n",
    "\n",
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181102cc-3698-477f-a7f6-db73c4c41e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "# add indexes\n",
    "index.add(feature_list_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5aefdf-9fee-466c-8b90-298dfcfe1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 100k\n",
    "D, I = index.search(feature_list_compressed[:100_000], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702a060-0609-463c-85f6-5acea9f3b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_top1, times_top5 = get_top_1_topn(I, 5)\n",
    "print('Times top1:', times_top1, '\\nTimes top5:', times_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243d197-934b-4eba-9be1-b86a1e957976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gpu; convert to cpu and save\n",
    "if use_gpu:\n",
    "    faiss.write_index(faiss.index_gpu_to_cpu(index), './models/pca-trainmini-faiss.index')\n",
    "if not use_gpu:   \n",
    "    faiss.write_index(index, './models/pca-trainmini-faiss.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc063e-39f4-4eec-88f6-a2e2ed95f019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
